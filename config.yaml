model:
  # Can be either a HuggingFace model ID or a local path
  # Examples:
  # - "Qwen/Qwen-7B"  # HuggingFace model ID
  # - "/path/to/local/model"  # Local model directory
  name: "../Qwen3-4B"  # Change this to your model path
  dtype: "float16"
  trust_remote_code: true
  # Optional: Set to true if you want to force download from HF even if local files exist
  force_download: false

sampling_strategies:
  - name: "default"
    temperature: 0.7
    top_p: 0.9
    max_tokens: 1000

scoring:
  format:
    answer_tag: "<answer>"
  strategies:
    exact_match:
      default_case_sensitive: false
      default_allow_partial: false
    numeric:
      default_tolerance: 0
      allow_scientific_notation: true
    list:
      default_order_matters: false
      default_allow_partial: false
      default_separators: [",", ";", "and", "&"]

output:
  base_dir: "output"
  save_individual: true
  save_consolidated: true
  metadata:
    include_timestamp: true
    include_model_version: true
    include_sampling_params: true 